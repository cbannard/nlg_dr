{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning a Machine Translation model\n",
        "\n",
        "In this sheet we take the multilingual model MBart and fine tune it for legal translation using a French-English corpus of legal documents. We will look at whether this improves using the BLEU score.\n"
      ],
      "metadata": {
        "id": "gpawPcFzbkiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "Bl9Ga_9E4Nlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW06kU3KRqF_"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MBart\n",
        "\n",
        "MBart is a multilingual encoder-decoder (sequence-to-sequence) model primarily intended for translation. A special language id token is added in both the source and target text depending on the language pair targeted."
      ],
      "metadata": {
        "id": "mgytPdcl_Db-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVHXqBfTPeaS"
      },
      "outputs": [],
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0Yx0q37PiYl"
      },
      "outputs": [],
      "source": [
        "device=\"cuda\"\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\").to(device)\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cadlaw corpus\n",
        "\n",
        "This is an English–French corpus built from Canadian legal documents. The corpus contains over 16 million words in each language and is composed of documents that are legally equivalent in both languages but not the result of a translation. The corpus is built upon enactments co-drafted by two jurists to ensure legal equality of each version and to re­flect the concepts, terms and institutions of two legal traditions.\n",
        "\n",
        "For more information see here:\n",
        "\n",
        "https://www.researchgate.net/publication/353471306_Cadlaws_-_An_English-French_Parallel_Corpus_of_Legally_Equivalent_Documents\n",
        "\n",
        "We are going to use it to fine tune MBart to perform the task of legal translation.\n"
      ],
      "metadata": {
        "id": "vZxILlJm_J-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh7UjFGVX5-_"
      },
      "outputs": [],
      "source": [
        "!gdown 1CPYP5JNzKzBqlKZMiGdfXD7y_0g-ruus\n",
        "!unzip cadlaws-fr-en.txt.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiVl49cOYgHQ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"cadlaws-fr-en.txt\",sep=\"\\t\",header=None)\n",
        "df.columns = [\"fr\",\"en\"]\n",
        "df=df.dropna()\n",
        "df=df.head(10000)\n",
        "ds=Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test=ds.train_test_split(test_size=500/df.shape[0],seed=99)"
      ],
      "metadata": {
        "id": "3yiI3FTF6mut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_test=train_test[\"test\"]"
      ],
      "metadata": {
        "id": "rez9AWRP6xW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_encodings = tokenizer(train_test[\"train\"][\"en\"], max_length=1024,truncation=True)\n",
        "input_encodings = tokenizer(train_test[\"train\"][\"fr\"], max_length=1024,truncation=True)\n",
        "ds_pt=Dataset.from_dict({\"input_ids\": input_encodings[\"input_ids\"], \"attention_mask\": input_encodings[\"attention_mask\"],\"labels\": target_encodings[\"input_ids\"]})\n",
        "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
        "ds_pt.set_format(type=\"torch\", columns=columns)"
      ],
      "metadata": {
        "id": "OiDy3jG6Zdf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD2Ny622ZBxj"
      },
      "outputs": [],
      "source": [
        "train_valid=ds_pt.train_test_split(test_size=500/(df.shape[0]-500),seed=99)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all we will evaluate the performance of untouched MBart on a test set of 500 utterances from Cadlaws using Bleu."
      ],
      "metadata": {
        "id": "rqDV91wXXQQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "model.to(\"cuda\")\n",
        "tokenizer.src_lang = \"fr_XX\"\n",
        "predictions=[]\n",
        "for i in range(len(ds_test[\"fr\"])):\n",
        "  input_ = tokenizer.batch_encode_plus(ds_test[\"fr\"][i:(i+1)], max_length=1024, pad_to_max_length=True,truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "  input_ids = input_['input_ids']\n",
        "  input_mask = input_['attention_mask']\n",
        "  responses_ft = model.generate(input_ids=input_ids.to(device),\n",
        "                         attention_mask=input_mask.to(device),\n",
        "                         num_beams=100,\n",
        "                         no_repeat_ngram_size=2,\n",
        "                         early_stopping=True,\n",
        "                         num_return_sequences=1,\n",
        "                         max_length=1024,\n",
        "                          )\n",
        "  predictions.extend(tokenizer.batch_decode(responses_ft, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "_e4uWLnQ75AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_vanilla = predictions"
      ],
      "metadata": {
        "id": "Fr833cuKXn47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "predictions\n",
        "references=[ds_test[\"en\"]]\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "bleu.add(predictions=str(predictions_vanilla), references=str(references))\n",
        "bleu.compute()"
      ],
      "metadata": {
        "id": "C03WY6nE7xy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will fine tune MBart using the training section of Cadlaws. Please note that this will take many hours so I am including a downloadable version of a fine-tuned model below. To fine tune from scratch you will need to comment out the next few blocks."
      ],
      "metadata": {
        "id": "rQ6HYYRWXpNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN-QeMboa-H6"
      },
      "outputs": [],
      "source": [
        "#seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "#training_args = TrainingArguments(\n",
        "#    output_dir='fr-en', num_train_epochs=1, warmup_steps=500,\n",
        "#    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "#    weight_decay=0.01, logging_steps=10, push_to_hub=False,\n",
        "#    evaluation_strategy='steps', eval_steps=30, save_steps=1e6,gradient_accumulation_steps=128)\n",
        "\n",
        "#trainer = Trainer(model=model, args=training_args,\n",
        "#                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "#                  train_dataset=ds_pt[\"train\"],\n",
        "#                  eval_dataset=ds_pt[\"valid\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT7Bq-CEcRrL"
      },
      "outputs": [],
      "source": [
        "#!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va9cNnXGcVDe"
      },
      "outputs": [],
      "source": [
        "#import wandb\n",
        "#from huggingface_hub import notebook_login\n",
        "\n",
        "#notebook_login()\n",
        "#wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "potw4Y9ucbq5"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "#torch.cuda.empty_cache()\n",
        "#trainer.train()\n",
        "# To save your fine-tuned model:\n",
        "#trainer.save_model(\"en-fr-legal-mbart\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To download and load the already fine-tuned model run the next cell."
      ],
      "metadata": {
        "id": "BgVSSWGWYOFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1V5Ib_QwDqfw_Qbjyg1lZxcuHjX4wZlLP\n",
        "!gunzip en-fr-legal-mbart.tar.gz\n",
        "!tar xf en-fr-legal-mbart.tar"
      ],
      "metadata": {
        "id": "cnBhLiyIYWpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\"\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"./en-fr-legal-mbart\").to(device)\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"./en-fr-legal-mbart\")\n"
      ],
      "metadata": {
        "id": "aNCN3NSGZTNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can evaluate this model using Bleu."
      ],
      "metadata": {
        "id": "TE3f0XypYZw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "model.to(\"cuda\")\n",
        "tokenizer.src_lang = \"fr_XX\"\n",
        "predictions=[]\n",
        "for i in range(len(ds_test[\"fr\"])):\n",
        "  input_ = tokenizer.batch_encode_plus(ds_test[\"fr\"][i:(i+1)], max_length=1024, pad_to_max_length=True,truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "  input_ids = input_['input_ids']\n",
        "  input_mask = input_['attention_mask']\n",
        "  responses_ft = model.generate(input_ids=input_ids.to(device),\n",
        "                         attention_mask=input_mask.to(device),\n",
        "                         num_beams=100,\n",
        "                         no_repeat_ngram_size=2,\n",
        "                         early_stopping=True,\n",
        "                         num_return_sequences=1,\n",
        "                         max_length=1024,\n",
        "                          )\n",
        "  predictions.extend(tokenizer.batch_decode(responses_ft, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "2_olL8HnJcwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "UMj3Ziof3tdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "predictions\n",
        "references=[ds_test[\"en\"]]\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "bleu.add(predictions=str(predictions), references=str(references))\n",
        "bleu.compute()"
      ],
      "metadata": {
        "id": "0nnREghp0u7B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}