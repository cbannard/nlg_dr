{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF1yRpTqq_X1"
      },
      "source": [
        "# Training / Fine-tuning a Text-to-Phon model\n",
        "\n",
        "We are going to look at model fine-tuning by taking a general purpose language model and fine-tuning it to translate text to IPA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULhlBcDPq_X2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U\n",
        "!pip install transformers -U\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBdlfSheCGkv"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "import accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"phonemetransformers/IPA-BabyLM\", \"strict_small\")"
      ],
      "metadata": {
        "id": "rhFxvhNZHQy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8QVrtgACGk1"
      },
      "source": [
        "### Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzpwXQAr2WjH"
      },
      "source": [
        "To fine tune BART from scratch uncomment the next five blocks of code and run. Note though that it will take a good few hours to run for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "#device=\"cuda\"\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "#model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\").to(device)"
      ],
      "metadata": {
        "id": "8t0uTXJ9ZylA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenset = list(set(str.split(' '.join(ds[\"train\"][:][\"phonemized_utterance\"]))))\n",
        "\n",
        "#print(len(tokenizer))  # 28996\n",
        "#tokenizer.add_tokens(tokenset)\n",
        "#print(len(tokenizer))  # 28997\n",
        "\n",
        "#model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "#def convert_examples_to_features(example_batch):\n",
        "#    input_encodings = tokenizer(example_batch[\"text\"], max_length=1024,\n",
        "#                                truncation=True)\n",
        "\n",
        "#    with tokenizer.as_target_tokenizer():\n",
        "#        target_encodings = tokenizer(example_batch[\"phonemized_utterance\"], max_length=1024,\n",
        "#                                     truncation=True)\n",
        "\n",
        "#    return {\"input_ids\": input_encodings[\"input_ids\"],\n",
        "#            \"attention_mask\": input_encodings[\"attention_mask\"],\n",
        "#            \"labels\": target_encodings[\"input_ids\"]}\n",
        "\n",
        "#ds_pt = ds.map(convert_examples_to_features, batched=True)\n",
        "#columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
        "#ds_pt.set_format(type=\"torch\", columns=columns)\n",
        "\n",
        "#from transformers import DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
        "\n",
        "#seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "#training_args = TrainingArguments(\n",
        "#    output_dir='text-to-phon', num_train_epochs=1, warmup_steps=500,\n",
        "#    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "#    weight_decay=0.01, logging_steps=10, push_to_hub=False,\n",
        "#    evaluation_strategy='steps', eval_steps=2500, save_steps=1e6,gradient_accumulation_steps=128)\n",
        "\n",
        "#trainer = Trainer(model=model, args=training_args,\n",
        "#                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "#                  train_dataset=ds_pt[\"train\"],\n",
        "#                  eval_dataset=ds_pt[\"valid\"])\n"
      ],
      "metadata": {
        "id": "FlB37FuBZOYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efPKAIdJ2WjH"
      },
      "outputs": [],
      "source": [
        "#!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnU37S9eCGk2"
      },
      "outputs": [],
      "source": [
        "#import wandb\n",
        "#from huggingface_hub import notebook_login\n",
        "\n",
        "#notebook_login()\n",
        "#wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcHfDkIICGk2"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "#torch.cuda.empty_cache()\n",
        "#trainer.train()\n",
        "# To save your fine-tuned model:\n",
        "#trainer.save_model(\"dialogue-summ-model-bart\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use a pre-tuned (for one-epoch only so performance isn't great yet) model run the following"
      ],
      "metadata": {
        "id": "fWb6wZlcpOl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1VAJMdR2kfHQkJRYQToLT8oHXEYfKJbZP\n",
        "\n",
        "!gunzip bart-text-to-phon.tar.gz\n",
        "!tar xf bart-text-to-phon.tar"
      ],
      "metadata": {
        "id": "OG225r5ppF2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "model_ckpt=\"bart-text-to-phon\"\n",
        "device=\"cuda\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "id": "PYE4KEP8p0Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikaKcLsfCGk2"
      },
      "source": [
        "### Translating new input to IPA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_utterance = \"mummy\"\n",
        "input_ = tokenizer(input_utterance, max_length=1024, truncation=True, return_tensors=\"pt\")\n",
        "device=\"cuda\"\n",
        "input_ids = input_['input_ids']\n",
        "input_mask = input_['attention_mask']\n",
        "responses = model.generate(input_ids=input_ids.to(device),\n",
        "                         attention_mask=input_mask.to(device),\n",
        "                         num_beams=100,\n",
        "                         no_repeat_ngram_size=2,\n",
        "                         early_stopping=True,\n",
        "                         num_return_sequences=1,\n",
        "                         max_length=1024)\n",
        "tokenizer.batch_decode(responses, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "UdzQr8iZLb0X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}